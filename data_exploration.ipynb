{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/isabelcorpus/.pyenv/versions/3.9.0/lib/python3.9/site-packages')\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from analysis_helper import *\n",
    "import json\n",
    "import seaborn as sns\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabelcorpus/sample_project/mind/analysis_helper/preprocessing.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_i].fillna('{}', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data: \n",
    "# load files, normalize embeddings, preprocess for analysis and modeling \n",
    "news = pd.read_csv(\"data/MINDsmall_train/news.tsv\", sep='\\t', \n",
    "                   names = [\"news_id\", \"category\", \"subcategory\", \"title\", \"abstract\", \"url\", \"title_entities\", \"abstract_entities\"])\n",
    "news = process_tsv(news, ['title_entities', 'abstract_entities'])\n",
    "\n",
    "entity_id, entity_vec = load_embeddings('data/MINDsmall_train/entity_embedding.vec')\n",
    "relation_id, relation_vec = load_embeddings('data/MINDsmall_train/relation_embedding.vec')\n",
    "\n",
    "entity_vec = normalize(entity_vec)\n",
    "\n",
    "# extract WikiData Knowledge Graph entity IDs for title and abstract\n",
    "news['title_entity_ids'] = extract_entity_list(news, 'title_entities', 'WikidataId')\n",
    "news['abstract_entity_ids'] = extract_entity_list(news, 'abstract_entities', 'WikidataId')\n",
    "\n",
    "# mean pool entity embeddings to create news embeddings  \n",
    "news_embeddings = mean_pooled_news_embeddings(entity_vec, entity_id, news, \"title_entity_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sentence-bert embeddings using pretrained SBERT model \n",
    "# load pre-trained sbert \n",
    "sbert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "title_embeddings = sbert.encode(np.vstack(news.title))\n",
    "\n",
    "# join embeddings with news metadata \n",
    "title_embedding_df = pd.DataFrame(zip(news.news_id, title_embeddings), columns = [\"news_id\", \"title_embedding\"])\n",
    "news_title_entity = pd.merge(title_embedding_df, news_embeddings, how = \"inner\", on = \"news_id\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
